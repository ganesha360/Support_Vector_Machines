# Support Vector Machines (SVM) â€” Binary Classification

## ğŸ“˜ Project Overview
This project demonstrates the implementation of **Support Vector Machines (SVM)** for both **linear and non-linear classification** using the **Breast Cancer dataset**.  
The goal is to classify whether a tumor is **Malignant (M)** or **Benign (B)** using SVMs with different kernels and visualize their performance.

---

## ğŸ§° Tools & Libraries Used
- **Python**
- **Pandas** â€“ data handling
- **NumPy** â€“ numerical operations
- **Matplotlib / Seaborn** â€“ visualization
- **Scikit-learn** â€“ for preprocessing, model training, and evaluation

---

## ğŸ§© Steps Performed

### 1ï¸âƒ£ Load & Explore Data
- Loaded the `breast-cancer.csv` dataset.
- Dropped unnecessary columns (like IDs).
- Checked for missing values and data types.

### 2ï¸âƒ£ Preprocessing
- Encoded the target column **(diagnosis)**:  
  - `M â†’ 1` (Malignant)  
  - `B â†’ 0` (Benign)
- Standardized all numeric features using **StandardScaler** for better model performance.

### 3ï¸âƒ£ Train-Test Split
- Split data into **80% training** and **20% testing** sets.

### 4ï¸âƒ£ Train Models
- Trained two models:
  - ğŸ”¹ **Linear Kernel SVM**
  - ğŸ”¹ **RBF Kernel SVM (non-linear)**

### 5ï¸âƒ£ Model Evaluation
- Evaluated using:
  - âœ… **Accuracy Score**
  - âœ… **Confusion Matrix**
  - âœ… **Classification Report** (Precision, Recall, F1-score)
- Compared linear vs RBF performance.

### 6ï¸âƒ£ Hyperparameter Tuning
- Tuned **C** and **gamma** values in the RBF kernel to improve performance.

### 7ï¸âƒ£ Cross-Validation
- Used **5-fold Cross Validation** to ensure model reliability and avoid overfitting.

### 8ï¸âƒ£ Visualization
- Applied **PCA** to reduce features to 2D.
- Plotted decision boundaries to show how SVM separates classes visually.

---

## ğŸ“Š Visualization Samples
| Visualization | Purpose |
|----------------|----------|
| `sns.heatmap(confusion_matrix)` | Show model performance |
| `plt.contourf()` | Display decision boundaries after PCA |
| `plt.scatter()` | Visualize class separation |

---

## âœ… Results
- Both SVM models achieved **high accuracy** in classifying cancerous vs non-cancerous cases.  
- **Linear SVM** performed well, but **RBF kernel** captured non-linear relationships better.  
- Achieved a strong **cross-validation accuracy**, confirming model stability.  
- Visualization clearly shows two separable clusters after PCA.

---

## ğŸ’¾ Files Included
- `breast-cancer.csv` â€” dataset  
- `SVM_Classification.ipynb` â€” full implementation code  
- `README.md` â€” documentation  

---

## ğŸ“š Learning Outcome
Through this project, I learned:
- How **SVMs** work for both linear and non-linear problems.  
- The impact of **kernel choice (linear vs RBF)** on model performance.  
- How to tune hyperparameters like **C** and **gamma**.  
- How to visualize **decision boundaries** using PCA.

---

## ğŸ§‘â€ğŸ’» Author
**Ganesh R**  
*(Junior AIML Engineer Trainee)*
